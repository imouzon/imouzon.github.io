% For LaTeX-Box: root = stat105_F15_exam1B.tex 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  File Name: stat105_F15_exam1B.tex
%  Purpose:
%
%  Creation Date: 24-09-2015
%  Last Modified: Wed May 11 12:07:59 2016
%  Created By:
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[addpoints]{examsetup}

\usepackage{etoolbox}
\usepackage{tikz,pgfplots}
\usepackage{graphicx, fancyhdr}
\usepackage{amsmath, amsfonts}
\usepackage{color}

%\input{stat105_exam1_info.tex}
\newcommand{\course}[1]{\ifstrempty{#1}{STAT 105}{STAT 105, Section #1}}
\newcommand{\sectionNumber}{A}
\newcommand{\examDate}{May 3, 2016}
\newcommand{\semester}{Spring 2016}
\newcommand{\examNumber}{III}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%-- : R code (Code in Document)
<<echo=FALSE, cache=FALSE, include = FALSE>>=
   library(ggplot2)
   library(dplyr)
   library(tidyr)
   library(xtable)

   options(scipen=999)

   theme_bw()

   Qfun <- function(x,p = NULL){
      x <- x[order(x)]

      n <- length(x)

      qs <- ((1:n) - .5)/n

      if(is.null(p)) return(qs)

      i <- floor(n*p + .5)

      Qp <- x[i] + (n*p + 0.5 - i)*(x[i+1] - x[i])

      return(Qp)
   }

   IQRange <- function(x) Qfun(x,.75) - Qfun(x,.25)

   samp <- round(rgamma(24, .1*10, .1),0)
   
@


\examCoverPage

\begin{questions}

\question[2]
(TRUE/FALSE) A random sample of 1000 student's Statistics exam scores was drawn from the population of all possible Stat scores (an unknown distribution).
Once the sample mean is computed, it can be viewed as the distribution/population mean.

\vspace{1cm}

\question[2]
(TRUE/FALSE) While trying to figure out the probability that the sample mean for a data of size 10 would exceed a value, we can apply the central limit theorem.

\vspace{1cm}

\question

%-- question1: R code (Code in Document)
<<question1, echo=FALSE, cache=TRUE, include = TRUE>>=
   set.seed(10012015.1)

   #precision vs accuracy
   high_pH <- round(rnorm(8,11.4,.1), 1)
   low_pH <- round(rnorm(8,3,.2), 1)
@

A pH meter is a tool used to determine the acidity of a liquid. 
During calibration, the repeated measures are taken on two different liquids, one with a known pH of 3 and the other with a known pH of 11.

\begin{itemize}

   \item Readings with pH = 11: $ \Sexpr{paste(high_pH,collapse=", ")} $ \\

   \item Readings with pH = 3: $ \Sexpr{paste(low_pH,collapse=", ")} $ \\

\end{itemize}


\begin{parts}
   \part[2] At what pH is the meter more accurate?

   \vspace{1cm}

   \part[2] At what pH is the meter more precise?

   \vspace{1cm}

\end{parts}

\vspace{1cm}

\question 
%-- functionsAndDatasets: R code (Code in Document)
<<functionsAndDatasets, echo=FALSE, cache=TRUE, include = TRUE>>=
   set.seed(1999)
   summary_sample <- c(round(rnorm(5,2,.3),1), 10.3)
@
A sample of size 5 was drawn from a population and the resulting observations are reported below. 
$$
   \Sexpr{paste(summary_sample,collapse=", ")}
$$
Using these observed values, report the following:

\vspace{0.5cm}

\begin{parts}

   \part[2] the mean  
   \vspace{1.5cm}

   \part[2] the median
   \vspace{1.5cm}

   \part[2] the variance 
   \vspace{2cm}

   \part[2] the standard deviation 
   \vspace{1.5cm}

\end{parts}

\newpage

\question
Portable pneumatic pumps have long been used by hobby machinists, but are gaining renewed interest as robotics are becoming a more common part of our daily lives.
Specifically, drones can make use of such pumps due to their weight benefits over hydraulic pumps with equivalent strength.
Amazon is experimenting with using such pumps in its delivery drones and is interested in factors effecting the lifetime of the pumps.

A team of engineers working for Amazon has been tasked with developing pumps for delivery drones that improve both time-in-flight (measured in hours) and the number of pump-actions (the number of times the drone uses the pump).
With those goals in mind, the team designed three pumps: a single-piston/single-stage design, a dual-piston/single-stage design, and a dual-piston/dual-stage design.
The engineers are testing the pumps with three types of compressed gas: OFN (oxygen-free nitrogen), Carbon dioxide, and Oxygen.
Concerned about environmental effects, the engineers selected four locations to test the drones in - San Antonio, Seattle, Lexington, and Amherst in which to test the drones.

In all four locations they tested the every design-gas combination in five drones (45 drones in each location).
The drones delivered 5 pound packages from an initial location to a location 2000 meters away, retrieved the package, and returned it to the original point.
The number of deliveries and the flight time were recorded for each drone.

Note: \((\text{3 designs}) \cdot (\text{3 gas types}) \cdot (\text{5 drones}) \cdot (\text{4 locations}) = \text{180 total drones}\)

The goal is to determine is to identify how to maximize both flight time and number of deliveries.

\begin{parts}
   \part[2] Is this an experiment or an observational study? Explain.

  \vspace{2cm}

  \part Identify each of the following and describe them as numeric (in which case, identify whether it is continuous or discrete) or categorcial (in which case list the possible levels).

  \vspace{1cm}

   \begin{subparts}
      \subpart[2] Identify the response variable(s):

      \vspace{2cm}

      \subpart[2] Identify the experimental variable(s):

      \vspace{2cm}

      \subpart[2] Blocking variable(s):

      \vspace{2cm}

   \end{subparts}

   \part[2] Identify two controlled variables used in this process.

   \vspace{2cm}

\end{parts}

\pagebreak

\question[12] 
The data reported below are the times to failure (in millions of cycles) of high-speed turbine engine bearings made out of two different compounds.

%-- compounds: R code (Code in Document)
<<compounds, echo=FALSE, cache=FALSE, results = 'asis'>>=

   # raw data from Chapter 3 # 8 (page 116)
   cmp1 <- c(3.03, 5.53, 5.60, 9.30, 9.92, 12.51, 12.95, 15.21, 16.04, 16.84)
   cmp2 <- c(3.19, 4.26, 4.47, 4.53, 4.67, 4.69, 5.78, 6.79, 9.37, 12.75)

   # add as data frame
   cmpb <- data.frame("bearing" = c(1:10, 1:10), "Compound" = rep(c("Compound 1","Compound 2"), each = 10), "lifetime" = c(cmp1, cmp2))
   cmpd <- cmpb %>% spread(bearing, lifetime)
   
   addtorow <- list()
   addtorow$pos <- list(0,0)
   addtorow$command <- c("& \\multicolumn{10}{c}{Bearing Number} \\\\\n", " & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\\\\n")
   print(xtable(cmpd), add.to.row = addtorow, include.rownames = FALSE, include.colnames = FALSE)

   Qfun <- function(x,p = NULL){
      x <- x[order(x)]

      n <- length(x)

      qs <- ((1:n) - .5)/n

      if(is.null(p)) return(qs)

      i <- floor(n*p + .5)

      Qp <- x[i] + (n*p + 0.5 - i)*(x[i+1] - x[i])

      return(Qp)
   }

@

For Compound 1, the first quartile is \Sexpr{Qfun(cmp1, 0.25)}, the median is is \Sexpr{Qfun(cmp1, 0.50)} and the interquartile range is \Sexpr{Qfun(cmp1, 0.75) - Qfun(cmp1, 0.25)}.

For Compound 2, the first quartile is \Sexpr{Qfun(cmp2, 0.25)}, the median is is \Sexpr{Qfun(cmp2, 0.50)} and the interquartile range is \Sexpr{Qfun(cmp2, 0.75) - Qfun(cmp2, 0.25)}.

\vspace{0.5cm}

Using the axes below, create a box plot for \textbf{time to failure} of each compound.

\begin{itemize}
   \item Label the values of the boundaries of the boxes
   \item Label the values the ends of the upper and lower whiskers
   \item Draw a star over unusual observations.
\end{itemize}

\textit{For any partial credit, show all work in the additional space}

\vspace{1cm}

%-- : R plot (results in document)
<<fig.width=8, fig.height=4, out.width='.9\\linewidth', echo=FALSE>>=
   cmpbx <- cmpb
   cmpbx$Compound <- gsub("Compound ","",cmpbx$Compound)
   ggplot(data = cmpbx, aes(x = Compound, y = lifetime, geom = "blank", ylab = "Bearing lifetime", xlab = "Compound")) +
   theme_bw() +
   theme(axis.ticks.y=element_blank()) + 
   ylab("Time to Failure") +
   scale_y_continuous(breaks=seq(0,17,1)) +
   coord_flip() 
@
\pagebreak

\question

%-- : R code (Code in Document)
<<echo=FALSE, cache=FALSE, include = TRUE>>=

   # Internally flawless, Ideal cut, colorless or nearly colorless
   dmnds <- diamonds %>% filter(clarity=="IF", cut == "Ideal", color %in% c("D", "E", "F"))

   dmnds$price <- dmnds$price/1000

   saveRDS(file = "dmnds.rds", dmnds)

   dmndscsv <- dmnds[,c("carat", "price")]
   dmndscsv$carat_sq <- dmndscsv$carat^2

   write.csv(file = "dmnds.csv", dmndscsv, row.names=FALSE)

   dmnds <- readRDS("dmnds.rds")

   nrows <- nrow(dmnds)

   sum_x <- sum(dmnds$carat)

   sum_x_sq <- sum(dmnds$carat*dmnds$carat)

   sum_y <- sum(dmnds$price)

   sum_y_sq <- sum(dmnds$price*dmnds$price)

   sum_xy <- sum(dmnds$carat*dmnds$price)

   obstopred <- dmnds[35,c("carat", "price")]
   names(obstopred) <- c("x", "y")

@

The quality of a diamond is often described in terms of the four C's:
carat (the diamonds mass, with 1 carat = 200 milligrams), 
cut (a description of how well the diamond has been shaped),
color (the less color the more rare),
clarity (a description of the flaws in the diamond).
Of these, carat is the most easily understood in terms of its impact on the diamonds value: 
all things being equal, the larger the diamond the higher its value.

The following plot shows the sale price of \Sexpr{nrow(dmnds)} diamonds (in thousands of dollars), which were appraised by experts as having an ideal cut, internally flawless clarity, and being colorless or essentially colorless.

%-- : R figure (code in document - set include=FALSE to remove)
\Sexpr{fig.cap = 'Plot depicting the sale price of 375 diamonds with the same quality of cut, clarity, and color. There is a general pattern indicating that higher carat (i.e., the mass) is associated with higher price.'}
<<fig.width=5, fig.height=5, out.width='.5\\linewidth', fig.cap=fig.cap, fig.pos="h", fig.align = "center", echo=FALSE>>=

   ggplot(data = dmnds, aes(x = carat, y = price)) + geom_point() + theme_bw()

@

Here are some summaries of the data (using carat as the $x$-value and price as the $y$-value):

$$
   \sum_{i=1}^{\Sexpr{nrows}} x_i = \Sexpr{sum_x} \hspace{3cm} \sum_{i=1}^{\Sexpr{nrows}} x_i^2 = \Sexpr{sum_x_sq} \\
$$

$$
   \sum_{i=1}^{\Sexpr{nrows}} y_i = \Sexpr{sum_y} \hspace{3cm} \sum_{i=1}^{\Sexpr{nrows}} y_i^2 = \Sexpr{sum_y_sq} \\
$$

$$
   \sum_{i=1}^{\Sexpr{nrows}} x_i y_i = \Sexpr{sum_xy}
$$

\newpage

\begin{parts}
   \part
   The following parts are based on using a linear relationship between carat ($x$) and price ($y$).
   \begin{subparts}
      \subpart[5] Using the above summaries, write the equation of the fitted linear relationship between carat and price.
      \vspace{3cm}
      \subpart[3] Using the fitted line, what do we suppose the price would be for a \Sexpr{obstopred[,"x"]} carat diamond?
      \vspace{3cm}
      \subpart[3] The actual price of a \Sexpr{obstopred[,"x"]} carat diamond in the data is \Sexpr{obstopred[,"y"]} thousand dollars. What is the residual for this specific diamond using the linear model?
      \vspace{3cm}
      \subpart[3] For the linear relationship, find $r$, the sample correlation coeffecient and $R^2$, the coeffecient of determination.
      \vspace{3cm}
      \subpart[3] Explain whether or not the fitted line did a good job describing the relationship between carat and price.
      \vspace{3cm}
   \end{subparts}

   \newpage 

   \part 
   A better fit may be found using a quadratic model, where price depends on carat and $\text{carat}^2$.
   The JMP output below comes from fitting a this quadratic relationship using price as the response (``\verb!price!") and 
   carat (\verb!carat!) and $\text{carat}^2$ (\verb!carat_sq!) as the model variables.

   \centerline{\includegraphics[scale=.35]{carat_sq_fit}}

   \begin{subparts}
      \subpart[5] Write the equation of the fitted quadratic relationship.
      \vspace{2cm}
      \subpart[3] Using the fitted quadratic relationship, what do we suppose the price would be for a \Sexpr{obstopred[,"x"]} carat diamond?
      \vspace{2cm}
      \subpart[3] The actual price of a \Sexpr{obstopred[,"x"]} carat diamond in the data is \Sexpr{obstopred[,"y"]} thousand dollars. What is the residual for this specific diamond using the quadratic model?
      \vspace{2cm}
      \subpart[3] Find the value of $R^2$ for the fitted quadratic relationship.
      \vspace{2cm}
      \subpart[3] Does it appear that a quadratic relationship is better than the linear relationship?
      \vspace{2cm}
   \end{subparts}
\end{parts}

\newpage

\question

A furniture company conducted a study of the tensile strength of wood joints. They examined the combinations of three joint type (butt joint, overlap joint, and beveled joint) and three wood type (pine, oak, and walnut), joined by the same resin glue.
For each wood/joint-type pair, four joints were made and the stress at failure (in psi) was recorded. The results are recorded below:

%-- : R code (Code in Document)
<<echo=FALSE, cache=TRUE, include = TRUE>>=

set.seed(1999)
wood_joint <- expand.grid(c("oak", "pine", "walnut"), c("beveled", "butt", "lap"))
wood_joints <- data.frame(rbind(wood_joint, wood_joint, wood_joint, wood_joint))

names(wood_joints) <- c("wood", "joint")

wood_joints$wood <- factor(wood_joints$wood)
wood_joints$joint <- factor(wood_joints$joint)

wood_joints$psi <- round(with(wood_joints, 1200 + 200*(wood == "oak") - 250*(wood == "pine") + 240*(wood == "walnut") - 300*(joint == "butt") + 200*(joint == "beveled") + 400*(joint == "lap")) + runif(nrow(wood_joints), 50, 100),1)

wood_joints <- wood_joints[order(wood_joints$joint),]
wood_joints <- wood_joints[order(wood_joints$wood),]

wood_joints %>% spread(joint)

wood_joints %>% spread(joint, psi, -wood)
wood_joints %>% group_by(wood, joint) %>% summarize(mn_psi = mean(psi)) %>% spread(joint, mn_psi)

wood_joints %>% group_by(wood, joint) %>% summarize(mn_psi = mean(psi)) %>% data.frame %>% arrange(joint) %>% group_by(joint) %>% summarize(dot_mn = mean(mn_psi))
@

The results are recorded below.

\begin{table}[h]
\centering
\begin{tabular}{lrrr}
   & \multicolumn{3}{c}{Joint} \\
\cline{2-4}
Wood & beveled & butt & lap \\ \hline \hline
oak     & \Sexpr{wood_joints$psi[1 + 0]}  & \Sexpr{wood_joints$psi[5 + 0]}  & \Sexpr{wood_joints$psi[9 + 0]} \\
        & \Sexpr{wood_joints$psi[1 + 1]}  & \Sexpr{wood_joints$psi[5 + 1]}  & \Sexpr{wood_joints$psi[9 + 1]} \\
        & \Sexpr{wood_joints$psi[1 + 2]}  & \Sexpr{wood_joints$psi[5 + 2]}  & \Sexpr{wood_joints$psi[9 + 2]} \\
        & \Sexpr{wood_joints$psi[1 + 3]}  & \Sexpr{wood_joints$psi[5 + 3]}  & \Sexpr{wood_joints$psi[9 + 3]} \\
pine    & \Sexpr{wood_joints$psi[13 + 0]}  & \Sexpr{wood_joints$psi[17 + 0]}  & \Sexpr{wood_joints$psi[21 + 0]} \\
        & \Sexpr{wood_joints$psi[13 + 1]}  & \Sexpr{wood_joints$psi[17 + 1]}  & \Sexpr{wood_joints$psi[21 + 1]} \\
        & \Sexpr{wood_joints$psi[13 + 2]}  & \Sexpr{wood_joints$psi[17 + 2]}  & \Sexpr{wood_joints$psi[21 + 2]} \\
        & \Sexpr{wood_joints$psi[13 + 3]}  & \Sexpr{wood_joints$psi[17 + 3]}  & \Sexpr{wood_joints$psi[21 + 3]} \\
walnut  & \Sexpr{wood_joints$psi[25 + 0]}  & \Sexpr{wood_joints$psi[29 + 0]}  & \Sexpr{wood_joints$psi[33 + 0]} \\
        & \Sexpr{wood_joints$psi[25 + 1]}  & \Sexpr{wood_joints$psi[29 + 1]}  & \Sexpr{wood_joints$psi[33 + 1]} \\
        & \Sexpr{wood_joints$psi[25 + 2]}  & \Sexpr{wood_joints$psi[29 + 2]}  & \Sexpr{wood_joints$psi[33 + 2]} \\
        & \Sexpr{wood_joints$psi[25 + 3]}  & \Sexpr{wood_joints$psi[29 + 3]}  & \Sexpr{wood_joints$psi[33 + 3]} \\
\hline
\end{tabular}
\end{table}

The following summaries may help in this problem:

%-- : R code (Code in Document)
<<echo=FALSE, cache=FALSE, include = FALSE>>=
   wood_sum <- wood_joints %>% group_by(wood, joint) %>% summarize(mn = mean(psi)) %>% spread(joint, mn) %>% data.frame

   wood_sum <- round(wood_sum[1:3,2:4],1)

   woodRowMeans <- round(rowMeans(wood_sum), 1)
   woodColMeans <- round(colMeans(wood_sum), 1)
   woodGrandMeans <- round(mean(woodColMeans), 1)

@

%  \begin{table}[h]
%  \centering
%  \begin{tabular}{lrrrr}
%     & \multicolumn{3}{c}{Joint} & \\
%  \cline{2-4}
%     Wood   & beveled                                                 & butt                                                   & lap \\ \cline{1-4}\cline{1-4}
%     oak    &    $\bar{y}_{11}$ = \Sexpr{wood_sum[1,1]}               & $\bar{y}_{12}$ = \Sexpr{wood_sum[1,2]}                 & $\bar{y}_{13}$ = \Sexpr{wood_sum[1, 3]}               &  $\bar{y}_{1 \cdot}$ = \Sexpr{woodRowMeans[1]} \\
%     pine   &    $\bar{y}_{21}$ = \Sexpr{wood_sum[2,1]}               & $\bar{y}_{22}$ = \Sexpr{wood_sum[2,2]}                 & $\bar{y}_{23}$ = \Sexpr{wood_sum[2, 3]}               &  $\bar{y}_{2 \cdot}$ = \Sexpr{woodRowMeans[2]} \\
%     walnut &    $\bar{y}_{31}$ = \Sexpr{wood_sum[3,1]}               & $\bar{y}_{32}$ = \Sexpr{wood_sum[3,2]}                 & $\bar{y}_{33}$ = \Sexpr{wood_sum[3, 3]}               &  $\bar{y}_{3 \cdot}$ = \Sexpr{woodRowMeans[3]} \\
%  \cline{1-4}
%            &    $\bar{y}_{\cdot 1}$ = \Sexpr{woodColMeans[1]}        &    $\bar{y}_{\cdot 2}$ = \Sexpr{woodColMeans[2]}       & $\bar{y}_{\cdot 3}$ = \Sexpr{woodColMeans[3]}         &    $\bar{y}_{\cdot \cdot}$ = \Sexpr{woodGrandMeans} \\
%  \end{tabular}
%  \end{table}


\begin{table}[h]
\centering
\begin{tabular}{lrrrr}
   & \multicolumn{3}{c}{Joint} & \\
\cline{2-4}
   Wood   & beveled                                                 & butt                                                   & lap \\ \cline{1-4}\cline{1-4}
   oak    &    $\bar{y}_{11}$ = \Sexpr{wood_sum[1,1]}               & $\bar{y}_{12}$ = \Sexpr{wood_sum[1,2]}                 & $\bar{y}_{13}$ = \Sexpr{wood_sum[1, 3]}               &  $\bar{y}_{1 \cdot}$ = \Sexpr{woodRowMeans[1]} \\
   pine   &    $\bar{y}_{21}$ = \Sexpr{wood_sum[2,1]}               & $\bar{y}_{22}$ = \Sexpr{wood_sum[2,2]}                 & $\bar{y}_{23}$ = \Sexpr{wood_sum[2, 3]}               &  $\bar{y}_{2 \cdot}$ = \Sexpr{woodRowMeans[2]} \\
   walnut &                                                         & $\bar{y}_{32}$ = \Sexpr{wood_sum[3,2]}                 & $\bar{y}_{33}$ = \Sexpr{wood_sum[3, 3]}               &  $\bar{y}_{3 \cdot}$ = \Sexpr{woodRowMeans[3]} \\
\cline{1-4}
          &    $\bar{y}_{\cdot 1}$ = \Sexpr{woodColMeans[1]}        &                                                        & $\bar{y}_{\cdot 3}$ = \Sexpr{woodColMeans[3]}         &    $\bar{y}_{\cdot \cdot}$ = \Sexpr{woodGrandMeans} \\
\end{tabular}
\end{table}


\begin{parts}

   \part[2] Report the value of $\bar{y}_{31}$
   \vspace{2cm}

   \part[2] Report the value of $\bar{y}_{\cdot 2}$
   \vspace{2cm}

   \part[3] Find the fitted main effect of wood type, $a_1$, $a_2$, and $a_3$, that you would get from factorial model that ignores interactions.
   \vspace{3cm}

   \newpage

   \part[3] Ignoring possible interactions, give the estimated values $\hat{y}_{22}$ and $\hat{y}_{23}$.
   \vspace{3cm}

   \part[2] How do the estimated values computed above compare to the average for the same combinations seen in the data? 
            Does it appear that ignoring interactions was a good choice?
   \vspace{2cm}

   \part[5] Using the template below, create a profile plot for this data:

%-- : R plot (results in document)
<<fig.width=8, fig.height=6, out.width='.7\\linewidth', fig.align="center",echo=FALSE>>=
   p <- ggplot(data = wood_joints, aes(x=wood,y=psi,xlab="Wood Type",ylab="Stress at Failure (psi)"))
   p + geom_blank() + theme_bw()
@

   \part[2] Using the plot does it appear that there are interactions between wood type and joint type? Which combination would you recommend if we want the highest Stress at Failure?
   \vspace{2cm}
\end{parts}

\newpage
 
\question

Let $X$ be a normal random variable with a mean of 5 and a varaince of 4 (i.e., $X \sim N(5,4)$) and let $Z$ be a random variable following a standard normal distribution.
Find the following probabilities (note: the attached standard normal probability table may be helpful):
\begin{parts}
     \part[2] $P(Z \le 1.5)$

 %-- : R code (Code in Document)
<<echo=TRUE, cache=TRUE, include = TRUE>>=
   pnorm(1.5)

   2*pnorm(-1.25)

   pnorm(9,5,2) - pnorm(1,5,2)

   pnorm(2,0,1) - pnorm(-2,0,1)
   
@
     
     \vspace{2cm}

     \part[2] $P(|Z| \ge 1.25)$

     \vspace{2cm}

     \part[2] $P(1 \le X < 9)$

     \vspace{2cm}

     \part[2] $P(|X| \le 5)$

     \vspace{2cm}

\end{parts}

\question 
 
 Suppose that $X$ is a continuous random variable with probability density function (pdf):
 $$
 f(x) = 
 \begin{cases}
     0 &  x < 0 \\
     2 e^{-2x} &  x \ge 0
 \end{cases}
 $$

 %-- : R code (Code in Document)
 <<echo=TRUE, cache=TRUE, include = TRUE>>=

    1 - exp(-2*1)

    1 - (1 - exp(-2*2))
    
 @
 
 
 \begin{parts}
 
 \part[3] Find F(x), the cumulative probability function.
 
      \vspace{3cm}
 
 \part[3] What is the probability that $X$ takes a value less than 1?
 
      \vspace{2cm}
 
 \part[3] What is the probability that $X$ takes a value greater than 2?
 
      \vspace{2cm}
 
 \end{parts}
 
 \newpage
 
 \question
 
 Consider the following scenario:

 A fair die is rolled and the number of dots facing up is counted.
 For each dot facing up on the die, a fair coin is flipped and the number of times the coin lands heads up is recorded.
 \begin{itemize}
    \item let $N$ be the number of dots facing up from the roll of the die
    \item let $X$ be the number of heads resulting from the flips of the coin.
 \end{itemize}

 Hint: if we roll a 5 then $N = 5$ and we will toss the coin 5 times. If we consider landing on heads to be a success, then we have the conditional distribution of $X | N = 5$ to be binomial(5, $0.5$).
 More generally, we can write:
 $$
 f_{X|N}(x|n) = \frac{n!}{(n - x)! x!} (0.5)^x (0.5)^{n - x}, x = 0, 1, ..., n
 $$
 and 0 otherwise.
 
 \begin{parts}
    \part[3] Find the marginal probability function for $N$, $f_N(n)$.
    \vspace{2cm}
    \part[3] Find the conditional probability that $X = 2$ given that $N = 4$, $f_{X|N}(2|4)$.
    \vspace{2cm}
    \part[3] Find the joint probability $f_{NX}(4,2)$.
    \vspace{2cm}
    \part[3] Find the joint probability $f_{NX}(3,2)$.
    \vspace{2cm}
    \part[3] Find $f_{X}(2)$.
    \vspace{2cm}
    \part[4] Find the probability that we rolled a 4 given that we had two heads from our coin flips, $f_{N|X}(4|2)$.
    \vspace{2cm}
 \end{parts}
 
\newpage

\question

An inspector examining the dependability of a certain gas pump fills 50 containers until the pump reads 1.00 gallons. 
If the pump is completely accurate, then each container should have 1.00 gallons of gasoline.
However, since nothing is completely consistent, there will be differences from one container to the next.

Suppose that it is known that the true standard deviation of the amount of gasoline the pump recognizes as 1.00 gallons is $\sigma = 0.2$ gallons.

The average of the 50 gallon samples is $\bar{x} = 0.992$ gallons

The following table may be useful:

\begin{table}[h]
   \centering
   \caption{z's for use in Two-sided Large-$n$ intervals for the mean}
   \begin{tabular}{cc}
      \hline \\
      Desired Confidence & $z$ \\
      \hline 
      80\% & 1.28 \\
      90\% & 1.645 \\
      95\% & 1.96 \\
      98\% & 2.33 \\
      99\% & 2.58 \\
      \hline 
   \end{tabular}
\end{table}

\begin{parts}

\part[4] Provide a 90\% confidence interval for the mean volume of gasoline recognized by the pump to be 1.00 gallons.
\vspace{2cm}

\part[4] Provide a 95\% confidence interval for the mean volume of gasoline recognized by the pump to be 1.00 gallons.
\vspace{2cm}

\part[4] Provide a 99\% confidence interval for the mean volume of gasoline recognized by the pump to be 1.00 gallons.
\vspace{2cm}

\part[4] Interpret these confidence intervals - is there evidence that the meter on the pump is not accurate?

\end{parts}


% % \question
% %    After running the O-ring experiment, the researchers found $\bar{x} = 50$ K and $\bar{y} = 53$ K. 
% %    Suppose that $\sigma_X^2 = 10$ and $\sigma_Y = 20$.
% % \begin{parts}
% %    \part[4] Provide a 90\% confidence interval for $\mu_X$.
% %    \vspace{3cm}
% %    \part[4] Provide a 99\% confidence interval for $\mu_X$.
% %    \vspace{3cm}
% %    \part[4] Provide a 95\% confidence interval for $\mu_Y$.
% %    \vspace{3cm}
% %    \part[6] Provide a 95\% confidence interval for $\mu_X - \mu_Y$ (hint: you can use the distribution of $\bar{D}$). Does this provide any evidence that one O-ring is better than the other?
% %    \vspace{3cm}
% %    \part[2] Is there any evidence that one O-ring is better than the other?
% % \end{parts}
% % 
% % \newpage
% % 
% % \question
% %    
% %    A company recently did a major overhaul to their server system hardware and is checking to make sure that there have been no changes in the download speed.
% %    The previous download speed had an average of 63.4 Mbps.
% %    A systems analyst took 10 readings on the download speeds during the course of a day to check. 
% %    Her results are below (in Mbps):
% % 
% % %-- : R code (Code in Document)
% % <<echo=FALSE, cache=TRUE, include = TRUE>>=
% % 
% % dwnld_speeds <- round(rnorm(10,0,.2) + 63.4,2)
% %    
% % @
% % 
% % \begin{center}
% %    \Sexpr{dwnld_speeds}
% % \end{center}
% % 
% % The sample average is \Sexpr{round(mean(dwnld_speeds),2)} and the sample variance is \Sexpr{round(var(dwnld_speeds),3)}.
% % 
% % \begin{parts}
% %    
% % 
% % \part[5] Provide a 90\% confidence interval for the mean download speed.
% % \vspace{2cm}
% % 
% % \part[5] Provide a 95\% lower confidence bound for the mean download speed.
% % \vspace{2cm}
% % 
% % \part[10] Conduct a hypothesis test at the 95\% confidence level for the null hypothesis $\mu = 63.4$ against the alternative $\mu \ne 63.4$. Include your hypothesis statement, the test statistic, the p-value, your decision rule, and your conclusion.
% % 
% % \end{parts}
% %    
 
\end{questions}
 
\end{document}
